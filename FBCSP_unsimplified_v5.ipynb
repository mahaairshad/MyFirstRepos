{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "FBCSP_unsimplified_v5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahaairshad/MyFirstRepos/blob/Feature-2/FBCSP_unsimplified_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdiDRtAGyiL",
        "colab_type": "code",
        "outputId": "a0d71bf6-ffdd-4a71-997b-d294baf83e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (45.2.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUE7y2aWHJk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_x9iK8HLDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qYQwxdAHPn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1-GmBB-nwfaKqDaymIjJfS5HZVxS97be8'})\n",
        "download.GetContentFile('DOWNLOAD.rar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTL5_DCQuI-",
        "colab_type": "code",
        "outputId": "92858054-7110-4ed9-e880-8411b999a1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"DOWNLOAD.rar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting DOWNLOAD.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/DOWNLOAD.rar\n",
            "patool:     with cwd='./Unpack_gpyuxcet'\n",
            "patool: ... DOWNLOAD.rar extracted to `Data_sample'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data_sample'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KduWx_MXJvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import butter, sosfilt, sosfreqz\n",
        "from numpy import linalg as LA\n",
        "from scipy import linalg as LAS\n",
        "from sklearn.model_selection import GridSearchCV    # Import library for grid search\n",
        "from sklearn import svm                             # Import SVM model library\n",
        "from sklearn import metrics                         # Evaluating Accuracy\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "from sklearn.metrics import cohen_kappa_score       # Evaluating Kappa score\n",
        "from sklearn.model_selection import cross_val_score # Cross Validation\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJHbbP45Z80o",
        "colab_type": "text"
      },
      "source": [
        "### 1. Access dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs4tjMOYZ80u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading single P's dataset\n",
        "# s : (1,1)\n",
        "# x : (3500,300,200)\n",
        "# y : (1,200)\n",
        "# c : ~(300,1)\n",
        "# ci : ~(300,1)\n",
        "# classInfo : (4,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n8PyvrRZ81A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotsS1 = loadmat('Data_sample/ParsedMEGData_P1.mat')\n",
        "annotsS2 = loadmat('Data_sample/ParsedMEGData_P1_S2.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-7t9zNHZ81Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdata1 = annotsS1['MEGdata']\n",
        "mtype1 = mdata1.dtype\n",
        "ndata1 = {n: mdata1[n][0,0] for n in mtype1.names}\n",
        "#ndata1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGcXLoPfZ81e",
        "colab_type": "code",
        "outputId": "5c9c965a-f783-4432-d938-2cc6c3a14074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "s_sess1=ndata1['s']\n",
        "x_sess1=ndata1['x']\n",
        "y_sess1=ndata1['y']\n",
        "c_sess1=ndata1['c']\n",
        "ci_sess1=ndata1['ci']\n",
        "class_info_Sess1=ndata1['classInfo']\n",
        "#class_info_Sess1=\n",
        "print(s_sess1.shape,'\\n',x_sess1.shape,'\\n', y_sess1.shape, '\\n', c_sess1.shape, '\\n',ci_sess1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1) \n",
            " (3500, 300, 200) \n",
            " (1, 200) \n",
            " (300, 1) \n",
            " (300, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sHKbEjzZ81n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdata2 = annotsS2['MEGdata']\n",
        "mtype2 = mdata2.dtype\n",
        "ndata2 = {n: mdata2[n][0,0] for n in mtype2.names}\n",
        "#ndata2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhfn7xuYZ811",
        "colab_type": "code",
        "outputId": "54bb123f-2dd2-47e1-b3e7-c1714ab5cc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "s_sess2=ndata2['s']\n",
        "x_sess2=ndata2['x']\n",
        "y_sess2=ndata2['y']\n",
        "c_sess2=ndata2['c']\n",
        "ci_sess2=ndata2['ci']\n",
        "class_info_Sess2=ndata2['classInfo']\n",
        "#class_info_Sess2=\n",
        "print(s_sess2.shape,'\\n',x_sess2.shape,'\\n', y_sess2.shape, '\\n', c_sess2.shape, '\\n',ci_sess2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1) \n",
            " (3500, 300, 200) \n",
            " (1, 200) \n",
            " (300, 1) \n",
            " (300, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9_4-sM4Z82B",
        "colab_type": "text"
      },
      "source": [
        "### 2. Considering the common channels from Session1 and Session2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6GVnL0-Z82D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmn_chnls=np.intersect1d(ci_sess1,ci_sess2)\n",
        "\n",
        "cmn_chnls=cmn_chnls.reshape(len(cmn_chnls),1) #reshaping so cmn_chnls, sess1_x and sess2_x have same shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QInt1wQRZ82K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_chnl_ind1=np.array([],dtype=int)\n",
        "valid_chnl_ind2=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,len(ci_sess1)):    #Stores the index of common channels b/w sess1_x and cmn_chnls\n",
        "    for j in range(0,len(cmn_chnls)):\n",
        "        if ci_sess1[i,0]==cmn_chnls[j,0]:\n",
        "            valid_chnl_ind1=np.append(valid_chnl_ind1,i)\n",
        "            \n",
        "for i in range(0,len(ci_sess2)):    #Stores the index of common channels b/w sess2_x and cmn_chnls\n",
        "    for j in range(0,len(cmn_chnls)):\n",
        "        if ci_sess2[i,0]==cmn_chnls[j,0]:\n",
        "            valid_chnl_ind2=np.append(valid_chnl_ind2,i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V05u2GHhZ82a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=x_sess1[:,valid_chnl_ind1,:] #(samples,channels,trials)\n",
        "data2=x_sess2[:,valid_chnl_ind2,:] #(samples,channels,trials)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Gm9CZTZ82r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Comibining session1 and session2 data (along 3rd axis(trials))\n",
        "MEGdata_s= s_sess1\n",
        "MEGdata_x= np.concatenate((data1,data2), axis=2)\n",
        "MEGdata_y= np.concatenate((y_sess1,y_sess2), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWaL1ZV1Z824",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEGdata_c= c_sess1[valid_chnl_ind1]\n",
        "MEGdata_ci= cmn_chnls.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpliaq6dZ83E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(MEGdata_s.shape,'\\n',MEGdata_x.shape,'\\n', MEGdata_y.shape, '\\n', MEGdata_c.shape, '\\n',MEGdata_ci.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MmX1W5qZ83L",
        "colab_type": "text"
      },
      "source": [
        "### 3. Implementation of Butterworth Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lN59xbhZ83N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frqBand=pd.read_csv('frqBands.csv',sep=','\n",
        "                    , header=None, index_col=None)\n",
        "smpRange=pd.read_csv('smpRange.csv',sep=','\n",
        "                    , header=None, index_col=None)\n",
        "baseRange=pd.read_csv('baseRange.csv',sep=','\n",
        "                    , header=None, index_col=None)\n",
        "classProb=pd.read_csv('classProb.csv',sep=','\n",
        "                    , header=None, index_col=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJFekbxQZ83W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Selecting Frequency band, Sampling range, Base range(noise) and Classes\n",
        "FreqBand=np.array([frqBand.iloc[0]]) #band\n",
        "FreqBand1=np.array([8, 12])\n",
        "FreqBand2=np.array([13, 17])\n",
        "FreqBand3=np.array([18, 22])\n",
        "FreqBand4=np.array([24, 28])\n",
        "SampRangeSec=np.array([smpRange.iloc[20]]) #actTs\n",
        "BaseRangeSec=np.array([baseRange.iloc[1]]) #baseTs\n",
        "Classes=np.array([classProb.iloc[0]]) #class1 class2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWHLcNLVZ83e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SampRange=s_sess1*SampRangeSec\n",
        "SampRangeind=np.arange(SampRange[0,0],SampRange[0,1],1,dtype=int)#saves index for given range of time\n",
        "BaseRange=s_sess1*BaseRangeSec\n",
        "BaseRangeind=np.arange(BaseRange[0,0],BaseRange[0,1],1,dtype=int)#saves index for given range of time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7LQHR3Z83s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separating data in classification of interest\n",
        "cMEGdata_y_ind=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,MEGdata_y.size): \n",
        "    if (MEGdata_y[0,i]==Classes[0,0])or(MEGdata_y[0,i]==Classes[0,1]):\n",
        "        cMEGdata_y_ind=np.append(cMEGdata_y_ind,i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6V8JOYaZ832",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cMEGdata_x=MEGdata_x[:,:,cMEGdata_y_ind] #(samples,channels,trials)\n",
        "cMEGdata_y=MEGdata_y[0,cMEGdata_y_ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWCwgfThZ84C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def butter_bandpass(lowcut, highcut, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        low = lowcut / nyq\n",
        "        high = highcut / nyq\n",
        "        sos = butter(order, [low, high], analog=True, btype='bandpass', output='sos')\n",
        "        return sos\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "        y = sosfilt(sos, data)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgL9hzoCZ84M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(samples,channels,trials)--> (channels,trials,samples)\n",
        "bMEGdata_x_1=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "bMEGdata_x_2=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "bMEGdata_x_3=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "bMEGdata_x_4=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "\n",
        "for trial in range(0,bMEGdata_x_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    for channel in range(0,bMEGdata_x_1[:,0,0].size): #(channels,trials,samples) size of channel\n",
        "        temp=cMEGdata_x[:,channel,trial] #(samples,channels,trials)\n",
        "        temp=temp-np.mean(temp[BaseRangeind])\n",
        "        f_temp1=butter_bandpass_filter(temp,FreqBand1[0],FreqBand1[1],MEGdata_s[0],4)\n",
        "        f_temp1=f_temp1[SampRangeind]\n",
        "        f_temp2=butter_bandpass_filter(temp,FreqBand2[0],FreqBand2[1],MEGdata_s[0],4)\n",
        "        f_temp2=f_temp2[SampRangeind]\n",
        "        f_temp3=butter_bandpass_filter(temp,FreqBand3[0],FreqBand3[1],MEGdata_s[0],4)\n",
        "        f_temp3=f_temp3[SampRangeind]\n",
        "        f_temp4=butter_bandpass_filter(temp,FreqBand4[0],FreqBand4[1],MEGdata_s[0],4)\n",
        "        f_temp4=f_temp4[SampRangeind]\n",
        "        bMEGdata_x_1[channel,trial,:]=f_temp1 #(channels,trials,samples)\n",
        "        bMEGdata_x_2[channel,trial,:]=f_temp2\n",
        "        bMEGdata_x_3[channel,trial,:]=f_temp3\n",
        "        bMEGdata_x_4[channel,trial,:]=f_temp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMxYdJ13Z84Y",
        "colab_type": "text"
      },
      "source": [
        "### 4.Separating train and validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGkq3fFmoq9",
        "colab_type": "text"
      },
      "source": [
        "Fband1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df_02S9Z84c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train/test data in 50:50\n",
        "size_Train_Test=int(bMEGdata_x_1[0,:,0].size/2)\n",
        "bMEGdata_x_Train_1=bMEGdata_x_1[:,0:size_Train_Test,:]\n",
        "bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "bMEGdata_x_Test_1=bMEGdata_x_1[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,bMEGdata_y_Train.size): \n",
        "    if (bMEGdata_y_Train[i]==Classes[0,0]):\n",
        "        c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "    else:\n",
        "        c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "# x and y values separated for class and 2\n",
        "c1_bMEGdata_x_Train_1=bMEGdata_x_Train_1[:,c1_bMEGdata_y_Train_ind,:]\n",
        "c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "c2_bMEGdata_x_Train_1=bMEGdata_x_Train_1[:,c2_bMEGdata_y_Train_ind,:]\n",
        "c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "# Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "c1_feat_Train_1=c1_bMEGdata_x_Train_1.reshape((c1_bMEGdata_x_Train_1[:,0,0].size,(c1_bMEGdata_x_Train_1[0,:,0].size*c1_bMEGdata_x_Train_1[0,0,:].size)))\n",
        "c2_feat_Train_1=c2_bMEGdata_x_Train_1.reshape((c2_bMEGdata_x_Train_1[:,0,0].size,(c2_bMEGdata_x_Train_1[0,:,0].size*c2_bMEGdata_x_Train_1[0,0,:].size)))\n",
        "\n",
        "c1_feat_Train_1.shape #(channels,trials*samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSUB9zzymrIg",
        "colab_type": "text"
      },
      "source": [
        "Fband2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh5jXZAmZ84j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train/test data in 50:50\n",
        "size_Train_Test=int(bMEGdata_x_2[0,:,0].size/2)\n",
        "bMEGdata_x_Train_2=bMEGdata_x_2[:,0:size_Train_Test,:]\n",
        "bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "bMEGdata_x_Test_2=bMEGdata_x_2[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,bMEGdata_y_Train.size): \n",
        "    if (bMEGdata_y_Train[i]==Classes[0,0]):\n",
        "        c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "    else:\n",
        "        c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "# x and y values separated for class and 2\n",
        "c1_bMEGdata_x_Train_2=bMEGdata_x_Train_2[:,c1_bMEGdata_y_Train_ind,:]\n",
        "c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "c2_bMEGdata_x_Train_2=bMEGdata_x_Train_2[:,c2_bMEGdata_y_Train_ind,:]\n",
        "c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "# Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "c1_feat_Train_2=c1_bMEGdata_x_Train_2.reshape((c1_bMEGdata_x_Train_2[:,0,0].size,(c1_bMEGdata_x_Train_2[0,:,0].size*c1_bMEGdata_x_Train_2[0,0,:].size)))\n",
        "c2_feat_Train_2=c2_bMEGdata_x_Train_2.reshape((c2_bMEGdata_x_Train_2[:,0,0].size,(c2_bMEGdata_x_Train_2[0,:,0].size*c2_bMEGdata_x_Train_2[0,0,:].size)))\n",
        "\n",
        "c1_feat_Train_2.shape #(channels,trials*samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVrH-Xt5mtDB",
        "colab_type": "text"
      },
      "source": [
        "Fband3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ATofrdZ84s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train/test data in 50:50\n",
        "size_Train_Test=int(bMEGdata_x_3[0,:,0].size/2)\n",
        "bMEGdata_x_Train_3=bMEGdata_x_3[:,0:size_Train_Test,:]\n",
        "bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "bMEGdata_x_Test_3=bMEGdata_x_3[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,bMEGdata_y_Train.size): \n",
        "    if (bMEGdata_y_Train[i]==Classes[0,0]):\n",
        "        c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "    else:\n",
        "        c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "# x and y values separated for class and 2\n",
        "c1_bMEGdata_x_Train_3=bMEGdata_x_Train_3[:,c1_bMEGdata_y_Train_ind,:]\n",
        "c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "c2_bMEGdata_x_Train_3=bMEGdata_x_Train_3[:,c2_bMEGdata_y_Train_ind,:]\n",
        "c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "# Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "c1_feat_Train_3=c1_bMEGdata_x_Train_3.reshape((c1_bMEGdata_x_Train_3[:,0,0].size,(c1_bMEGdata_x_Train_3[0,:,0].size*c1_bMEGdata_x_Train_3[0,0,:].size)))\n",
        "c2_feat_Train_3=c2_bMEGdata_x_Train_3.reshape((c2_bMEGdata_x_Train_3[:,0,0].size,(c2_bMEGdata_x_Train_3[0,:,0].size*c2_bMEGdata_x_Train_3[0,0,:].size)))\n",
        "\n",
        "c1_feat_Train_3.shape #(channels,trials*samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFXl97bLmvQn",
        "colab_type": "text"
      },
      "source": [
        "Fband4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvq7RzNpZ84y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train/test data in 50:50\n",
        "size_Train_Test=int(bMEGdata_x_4[0,:,0].size/2)\n",
        "bMEGdata_x_Train_4=bMEGdata_x_4[:,0:size_Train_Test,:]\n",
        "bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "bMEGdata_x_Test_4=bMEGdata_x_4[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,bMEGdata_y_Train.size): \n",
        "    if (bMEGdata_y_Train[i]==Classes[0,0]):\n",
        "        c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "    else:\n",
        "        c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "# x and y values separated for class and 2\n",
        "c1_bMEGdata_x_Train_4=bMEGdata_x_Train_4[:,c1_bMEGdata_y_Train_ind,:]\n",
        "c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "c2_bMEGdata_x_Train_4=bMEGdata_x_Train_4[:,c2_bMEGdata_y_Train_ind,:]\n",
        "c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "# Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "c1_feat_Train_4=c1_bMEGdata_x_Train_4.reshape((c1_bMEGdata_x_Train_4[:,0,0].size,(c1_bMEGdata_x_Train_4[0,:,0].size*c1_bMEGdata_x_Train_4[0,0,:].size)))\n",
        "c2_feat_Train_4=c2_bMEGdata_x_Train_4.reshape((c2_bMEGdata_x_Train_4[:,0,0].size,(c2_bMEGdata_x_Train_4[0,:,0].size*c2_bMEGdata_x_Train_4[0,0,:].size)))\n",
        "\n",
        "c1_feat_Train_4.shape #(channels,trials*samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1FV7JMCZ85J",
        "colab_type": "text"
      },
      "source": [
        "### 5. Implementation of CSP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UMnFzYZ85M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CSP_projectionMat(class1, class2):\n",
        "        #1 Find spatial covariance for both classes of data\n",
        "        C1= np.matmul(class1,np.transpose(class1))/np.trace(np.matmul(class1,np.transpose(class1)))\n",
        "        C2= np.matmul(class2,np.transpose(class2))/np.trace(np.matmul(class2,np.transpose(class2)))\n",
        "        #2 Find composite spatial covariance\n",
        "        Cc=C1+C2\n",
        "        #3 Find eigen vectors and eigen values for Cc\n",
        "        eigvalCc, eigvecCc= LA.eig(Cc)\n",
        "        ## form eigval & eigvec in descending order and form diagonal matrix for eigval\n",
        "        temp=np.sort(eigvalCc)  #sorts in ascending\n",
        "        eigvalCc=temp[::-1]     #sorts in descending\n",
        "        Cc_ind=np.argsort(temp) #finds arg for asc\n",
        "        Cc_ind=Cc_ind[::-1]     #finds arg for des\n",
        "        eigvalCc=np.diag(eigvalCc) #form diagonal matrix\n",
        "        eigvecCc=eigvecCc[:,Cc_ind] #finds respective eigen vectors for the eig values\n",
        "        #4 Find whitening transform\n",
        "        P=np.matmul(LA.inv(eigvalCc),np.transpose(eigvecCc))\n",
        "        P=np.sqrt(np.square(P)) #getting rid of the -ve values for simplicity here(MUST BE REMOVED)\n",
        "        P=np.sqrt(P)\n",
        "        #5 Find S1 and S2 for C1 and C2\n",
        "        S1=np.matmul(P,C1) #S1=PC1P'\n",
        "        S1=np.matmul(S1,np.transpose(P))\n",
        "        S2=np.matmul(P,C2) #S2=PC2P'\n",
        "        S2=np.matmul(S2,np.transpose(P))\n",
        "        #6 Find generalized eigenvector and eigenvalues for S1 and S2\n",
        "        eigvalB,B=LAS.eig(S1,S2, left=False, right=True)\n",
        "        #7 Find W\n",
        "        eigvalB=np.sort(eigvalB) #arranging in ascending to have the lowest eigenvalue on top and highest on bottom\n",
        "        B_ind=np.argsort(eigvalB)\n",
        "        B=B[:,B_ind]\n",
        "        W=np.matmul(np.transpose(B),P)\n",
        "        return W"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nR1rCfoZ85V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1=CSP_projectionMat(c1_feat_Train_1,c2_feat_Train_1)\n",
        "W2=CSP_projectionMat(c1_feat_Train_2,c2_feat_Train_2)\n",
        "W3=CSP_projectionMat(c1_feat_Train_3,c2_feat_Train_3)\n",
        "W4=CSP_projectionMat(c1_feat_Train_4,c2_feat_Train_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3LE5DI_Z85f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN DATA\n",
        "#Finding 2 best features for each trial\n",
        "Train_x_1=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2)) #bMEGdata_x_Train=(channels,trials,samples)\n",
        "Train_x_2=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2))\n",
        "Train_x_3=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2))\n",
        "Train_x_4=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2))\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Train_1[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W1),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Train_x_1[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Train_2[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W2),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Train_x_2[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Train_3[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W3),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Train_x_3[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Train_4[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W4),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Train_x_4[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "Train_x=np.hstack([Train_x_1,Train_x_2])\n",
        "Train_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sI4cq2Nl_UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST DATA\n",
        "#Finding 2 best features for each trial\n",
        "\n",
        "Test_x_1=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2)) #bMEGdata_x_Test=(channels,trials,samples)\n",
        "Test_x_2=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2))\n",
        "Test_x_3=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2))\n",
        "Test_x_4=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2))\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Test_1[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W1),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Test_x_1[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Test_2[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W2),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Test_x_2[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Test_3[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W3),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Test_x_3[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "    temp=bMEGdata_x_Test_4[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "    Z=np.matmul(np.transpose(W4),temp) #Z: CSP Features\n",
        "    Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "    Test_x_4[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "Test_x=np.hstack([Test_x_1,Test_x_2])\n",
        "Test_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etq7WDNdZ85s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_x.shape # X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwYzJymsZ854",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_y=bMEGdata_y_Train #Y_train\n",
        "Train_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_3JGdmRj8hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjpe8d59kHQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_y=bMEGdata_y_Test\n",
        "Test_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq-vbMopZ86G",
        "colab_type": "text"
      },
      "source": [
        "### 6. Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4b8qlacZ86O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM Classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfy4KzGJi-YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svc_param_selection(X, y, nfolds):\n",
        "    parameters = {'kernel': ['rbf']},\n",
        "    {'kernel': ['linear']}\n",
        "    SVM = svm.SVC()\n",
        "    grid_search = GridSearchCV(SVM, parameters, cv=nfolds) \n",
        "    grid_search.fit(X, y)\n",
        "    grid_search.best_estimator_\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "SVM_params=svc_param_selection(Train_x,Train_y, 10)\n",
        "print(SVM_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTJzI1JGjlkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stating SVM model\n",
        "SVM = svm.SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "    tol=0.001, verbose=False)\n",
        "\n",
        "# Training of SVM model using training set\n",
        "SVM.fit(Train_x, Train_y)\n",
        "\n",
        "# Predicting the trained model using the test set\n",
        "svm_predictions = SVM.predict(Train_x) #test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPHOD5OwqFbz",
        "colab_type": "text"
      },
      "source": [
        "### 7. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHCNrA7rnFMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------Evaluating SVM--------------------------\n",
        "print(\"Accuracy:\",acc(Train_y, svm_predictions)*100)#test #Calculating the accuracy for SVM model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTgNWK5-nRJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Kappa statistics: \",cohen_kappa_score(Train_y, svm_predictions))#test  # Calculating Kappa score for SVM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QcxDfh9nfzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(SVM, Train_x, Train_y, cv=10,scoring = make_scorer(acc))\n",
        "\n",
        "print(\"ACC: %0.2f +/- %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}